{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set `jupyter.notebookFileRoot` to `${workspaceFolder}`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import src.models.naive_bayes as naive_bayes\n",
    "import src.models.logreg as logreg\n",
    "from src.models.vectorization import CustomTfidfVectorizer\n",
    "import src.models.tokenization as tkn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweets: size  13683\n",
      "['Jolly Jovial #JeromePowell at the FOMC #Powell #FOMC #FOMCMeeting #RateCut #Rate #RateCuts #25bps #Economy #Inflation #Deflation #Economics #Fed #TheFed #FederalReserve $BTC #BTC #Bitcoin'\n",
      " 'Concept art of Devil May Cry when it was still in development as Resident Evil 4'\n",
      " '\\'\"I have this weird habit of,  when having spare time between projects,  just staring at my desktop and trying to build up the courage or motivation to start a new game. Like I don\\'\\'t like the commitment of starting a new game,  or always feel like there\\'\\'s something more productive.\"\\''\n",
      " \"'This is not a joke. I‚Äôve been through this exact experience with my boyfriend. When he was stressed or depressed,  he started using curse words and making inappropriate jokes. He made some pretty bad jokes and used some really inappropriate language. If you'\"\n",
      " \"'Social Justice is the topic that everyone seems to be talking about these days. A social justice movement has been growing in America for years,  but it took a really big push to make it a mainstream issue. It was'\"\n",
      " 'Your child is autistic but you voted for someone who wants to defund the department of education which would grant your child special learning accommodations but no yeah ‚ÄúJesus is king‚Äù'\n",
      " 'Time to get creative with NewYear2024! What‚Äôs your latest project? üé® #NewYear2024,'\n",
      " \"'I swear this wasn''t my fault!'\"\n",
      " \"'Use #fitness to get your first tweet out. Don‚Äôt forget to follow the fitness accounts of other users. Once you have a good following,  then you can start to create your own fitness accounts.'\"\n",
      " 'to coach football at USC‚Ä¶?']\n",
      "[0 0 0 1 1 0 1 0 1 0]\n",
      "AI tweets: 4127\n"
     ]
    }
   ],
   "source": [
    "#frame = pd.read_csv(\"dataset.csv\", delimiter=\",\", quotechar=\"'\", names=(\"tweet\", \"label\"))\n",
    "\n",
    "path = \"src/models/dataset.xlsx\" # adjust to where you keep the dataset\n",
    "\n",
    "frame = pd.read_excel(\n",
    "    path, \n",
    "    sheet_name=\"Worksheet\", \n",
    "    header=None, \n",
    "    usecols=\"A:B\", \n",
    "    names=(\"tweet\", \"label\")\n",
    ")\n",
    "\n",
    "X = frame[\"tweet\"].values\n",
    "y = frame[\"label\"].values \n",
    "\n",
    "print(\"tweets: size \", X.size)\n",
    "print(X[:10])\n",
    "print(y[:10])\n",
    "\n",
    "print(\"AI tweets:\", np.count_nonzero(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run if you wish to split phrases written in Pascal case\n",
    "X = list(map(tkn.split_pascals, X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=5000, test_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom-preprocessed sets\n",
    "custom_vec = CustomTfidfVectorizer(min_df=5, max_df_ratio=0.6)\n",
    "\n",
    "X_train_custom_prep = custom_vec.fit_transform(X_train)\n",
    "X_test_custom_prep = custom_vec.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sklearn-preprocessed sets\n",
    "sklearn_vec = TfidfVectorizer(min_df=5, max_df=0.6, sublinear_tf=True)\n",
    "\n",
    "X_train_sklearn_prep = sklearn_vec.fit_transform(X_train).toarray()\n",
    "X_test_sklearn_prep = sklearn_vec.transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mikolaj/ml/mann-vs-machine/src/models/logreg.py:11: RuntimeWarning: overflow encountered in exp\n",
      "  aux = ys - np.reciprocal(1 + np.exp(-xs @ beta))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy logreg custom/custom:  0.717\n",
      "Accuracy logreg sklearn/custom:  0.846\n"
     ]
    }
   ],
   "source": [
    "# Custom logistic regression \n",
    "lr = logreg.LogisticRegressionModel()\n",
    "\n",
    "## on custom-preprocessed data\n",
    "lr.train(X_train_custom_prep, y_train)\n",
    "\n",
    "accuracy = (lr.classify(X_test_custom_prep) == y_test).mean()\n",
    "print(\"Accuracy logreg custom/custom: \", accuracy)\n",
    "\n",
    "## on sklearn-preprocessed data\n",
    "lr.train(X_train_sklearn_prep, y_train)\n",
    "\n",
    "accuracy = (lr.classify(X_test_sklearn_prep) == y_test).mean()\n",
    "print(\"Accuracy logreg sklearn/custom: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy custom Bayes:  0.547\n"
     ]
    }
   ],
   "source": [
    "# Custom naive Bayes\n",
    "nb = naive_bayes.NaiveBayesModel()\n",
    "\n",
    "# it uses its own preprocessing\n",
    "X_train_bayes = nb.preprocess_set(X_train)\n",
    "X_test_bayes = nb.preprocess_set(X_test)\n",
    "\n",
    "nb.train(X_train_bayes, y_train)\n",
    "\n",
    "results = nb.classify(X_test_bayes)\n",
    "correct = 0\n",
    "for result, label in zip(results, y_test):\n",
    "    if result == label:\n",
    "        correct += 1\n",
    "acc = correct/1000\n",
    "print(\"Accuracy custom Bayes: \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy logreg custom/sklearn:  0.821\n",
      "Accuracy logreg sklearn/sklearn:  0.893\n"
     ]
    }
   ],
   "source": [
    "# Sklearn's LogisticRegression\n",
    "slr = LogisticRegression(penalty=None)\n",
    "\n",
    "## on custom-preprocessed data\n",
    "slr.fit(X_train_custom_prep, y_train)\n",
    "\n",
    "accuracy = (slr.predict(X_test_custom_prep) == y_test).mean()\n",
    "print(\"Accuracy logreg custom/sklearn: \", accuracy)\n",
    "\n",
    "## on sklearn-preprocessed data\n",
    "slr.fit(X_train_sklearn_prep, y_train)\n",
    "\n",
    "accuracy = (slr.predict(X_test_sklearn_prep) == y_test).mean()\n",
    "print(\"Accuracy logreg sklearn/sklearn: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Bayes custom/sklearn:  0.811\n",
      "Accuracy Bayes sklearn/sklearn:  0.875\n"
     ]
    }
   ],
   "source": [
    "# Sklearn's ComplementNB\n",
    "cnb = ComplementNB()\n",
    "\n",
    "## on custom-preprocessed data\n",
    "cnb.fit(X_train_custom_prep, y_train)\n",
    "\n",
    "accuracy = (cnb.predict(X_test_custom_prep) == y_test).mean()\n",
    "print(\"Accuracy Bayes custom/sklearn: \", accuracy)\n",
    "\n",
    "## on sklearn-preprocessed data\n",
    "cnb.fit(X_train_sklearn_prep, y_train)\n",
    "\n",
    "accuracy = (cnb.predict(X_test_sklearn_prep) == y_test).mean()\n",
    "print(\"Accuracy Bayes sklearn/sklearn: \", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
